{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b944054e",
   "metadata": {},
   "source": [
    "# MLP regression for absorbance computation\n",
    "\n",
    "This code will read the csv file with the data for the computation of a model to\n",
    "predict absorbance.\n",
    "\n",
    "It will use a multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b868df",
   "metadata": {},
   "source": [
    "# Step 1 - Loading the Required Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc20f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46617c",
   "metadata": {},
   "source": [
    "# Step 2 - Reading the Data and Performing Basic Data Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29267be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c19ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Abs\n",
      "0   -1.355572\n",
      "1   -3.922080\n",
      "2   -3.091707\n",
      "3   -1.146734\n",
      "4   -1.174340\n",
      "..        ...\n",
      "307  0.687039\n",
      "308  0.628481\n",
      "309  0.781131\n",
      "310  0.862545\n",
      "311  0.884988\n",
      "\n",
      "[312 rows x 1 columns]\n",
      "         Time      Dope         a         c      Size\n",
      "0   -1.525075 -0.853334  0.290804  0.285510  0.073190\n",
      "1   -1.525075 -0.853334  0.281575  0.293431  0.666677\n",
      "2   -1.525075 -0.853334  0.295419  0.284069 -0.096378\n",
      "3   -1.525075 -0.853334  0.285036  0.289831  0.459427\n",
      "4   -1.525075 -0.113778  0.290804  0.285510  0.073190\n",
      "..        ...       ...       ...       ...       ...\n",
      "307  1.525075  1.365334  0.295419  0.284069 -0.096378\n",
      "308  1.525075  1.365334  0.285036  0.289831  0.459427\n",
      "309  1.525075 -1.592889 -3.458501 -3.458524 -3.308746\n",
      "310  1.525075 -1.592889 -3.458501 -3.458524 -3.308746\n",
      "311  1.525075 -1.592889 -3.458501 -3.458524 -3.308746\n",
      "\n",
      "[312 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data. The original dataset includes names in first row\n",
    "#dataset = pd.read_csv(\"dataframe_ZnER_EC_clean.csv\")\n",
    "dataset = pd.read_csv(\"database_EC_norm_trans.csv\")\n",
    "\n",
    "# Separate the class from the attributes\n",
    "target = pd.DataFrame(dataset, columns= ['Abs'])\n",
    "\n",
    "print (target)\n",
    "\n",
    "attributes= dataset.loc[ : , dataset.columns != 'Abs']\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111196fc",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e40d439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into  training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(\n",
    "    attributes,target,test_size=0.33, random_state=50)\n",
    "\n",
    "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13833ec",
   "metadata": {},
   "source": [
    "# Train (fit) an MLP\n",
    "Train an MLP as a regression model. In this case, we will make a three layers model. First with 100 neurons, second with 50 and last with 10. Relu activation, and Solver Adam Once the model is trained, we ask it to predict values and store them on y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f964224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gildardo/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Train one model with raw data to establish a reference.\n",
    "# In this case, we will train a MLP\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Initializing the MLPRegressor\n",
    "regr = MLPRegressor(hidden_layer_sizes=(500,100,40), max_iter=10000,\n",
    "                           activation = 'relu',solver='lbfgs',random_state=1)\n",
    "\n",
    "#Fitting the training data to the network\n",
    "regr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Predicting y for X_val\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a8596",
   "metadata": {},
   "source": [
    "# Compute accuracy. \n",
    "The score by default is r^2.\n",
    "\n",
    "R^2(coefficient of determination) regression score function.\n",
    "\n",
    "Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \n",
    "R^2 score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a58fb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9164748384906659"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f1b5b9",
   "metadata": {},
   "source": [
    "Now use a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb38a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression() \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting y for X_val\n",
    "y_pred2= model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv') \n",
    "print(df.shape)\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313b9d2",
   "metadata": {},
   "source": [
    "# Step 3 - Creating Arrays for the Features and the Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ['diabetes'] \n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976bfa15",
   "metadata": {},
   "source": [
    "Step 4 - Creating the Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[predictors].values\n",
    "\n",
    "y = df[target_column].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bda68d",
   "metadata": {},
   "source": [
    "Step 5 - Building, Predicting, and Evaluating the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
    "\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "\n",
    "predict_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_train,predict_train))\n",
    "\n",
    "print(classification_report(y_train,predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predict_test))\n",
    "\n",
    "print(classification_report(y_test,predict_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
